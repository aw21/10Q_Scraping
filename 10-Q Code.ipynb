{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing built-in libraries (no need to install these)\n",
    "import sys\n",
    "import re\n",
    "import os\n",
    "from time import gmtime, strftime\n",
    "from datetime import datetime, timedelta\n",
    "import unicodedata\n",
    "\n",
    "# Importing libraries you need to install\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import requests\n",
    "import bs4 as bs\n",
    "from lxml import html\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import shutil\n",
    "import re\n",
    "from dateutil.parser import parse\n",
    "from datetime import datetime, timedelta\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import numpy as np\n",
    "from bs4 import NavigableString\n",
    "import html2text\n",
    "from nltk import tokenize\n",
    "from collections import namedtuple\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "original_directory = \"/Users/andrewwang/MyDocuments/10Q_Scraping\"\n",
    "os.chdir(original_directory)\n",
    "pathname_10k = original_directory + '/10_K_Docs'\n",
    "pathname_10q = original_directory + '/10_Q_Docs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"SP500_Tickers.csv\") as f:\n",
    "    tickers = [row.split()[0] for row in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MapTickerToCik(tickers):\n",
    "    url = 'http://www.sec.gov/cgi-bin/browse-edgar?CIK={}&Find=Search&owner=exclude&action=getcompany'\n",
    "    cik_re = re.compile(r'.*CIK=(\\d{10}).*')\n",
    "\n",
    "    cik_dict = {}\n",
    "    for ticker in tqdm(tickers): # Use tqdm lib for progress bar\n",
    "        results = cik_re.findall(requests.get(url.format(ticker)).text)\n",
    "        if len(results):\n",
    "            cik_dict[str(ticker).lower()] = str(results[0])\n",
    "    \n",
    "    return cik_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 505/505 [05:24<00:00,  1.56it/s] \n"
     ]
    }
   ],
   "source": [
    "cik_dict = MapTickerToCik(tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cik</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ticker</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mmm</th>\n",
       "      <td>0000066740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abt</th>\n",
       "      <td>0000001800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbv</th>\n",
       "      <td>0001551152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abmd</th>\n",
       "      <td>0000815094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acn</th>\n",
       "      <td>0001467373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               cik\n",
       "ticker            \n",
       "mmm     0000066740\n",
       "abt     0000001800\n",
       "abbv    0001551152\n",
       "abmd    0000815094\n",
       "acn     0001467373"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean up the ticker-CIK mapping as a DataFrame\n",
    "ticker_cik_df = pd.DataFrame.from_dict(data=cik_dict, orient='index')\n",
    "ticker_cik_df.reset_index(inplace=True)\n",
    "ticker_cik_df.columns = ['ticker', 'cik']\n",
    "ticker_cik_df['cik'] = [str(cik) for cik in ticker_cik_df['cik']]\n",
    "ticker_cik_df = ticker_cik_df.set_index('ticker')\n",
    "ticker_cik_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ticker_cik_df.to_csv('ticker_cik_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def WriteLogFile(log_file_name, text):\n",
    "    \n",
    "    '''\n",
    "    Helper function.\n",
    "    Writes a log file with all notes and\n",
    "    error messages from a scraping \"session\".\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    log_file_name : str\n",
    "        Name of the log file (should be a .txt file).\n",
    "    text : str\n",
    "        Text to write to the log file.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    None.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    with open(log_file_name, \"a\") as log_file:\n",
    "        log_file.write(text)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ScrapeDocument(ticker, browse_url_base, filing_url_base, doc_url_base, cik, log_file_name, is10K, num_files_to_scrape):\n",
    "    \n",
    "    '''\n",
    "    Scrapes all 10-Ks and 10-K405s for a particular \n",
    "    CIK from EDGAR.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    browse_url_base : str\n",
    "        Base URL for browsing EDGAR.\n",
    "    filing_url_base : str\n",
    "        Base URL for filings listings on EDGAR.\n",
    "    doc_url_base : str\n",
    "        Base URL for one filing's document tables\n",
    "        page on EDGAR.\n",
    "    cik : str\n",
    "        Central Index Key.\n",
    "    log_file_name : str\n",
    "        Name of the log file (should be a .txt file).\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    None.\n",
    "    \n",
    "    '''\n",
    "    os.chdir(original_directory)\n",
    "    \n",
    "    # Check if we've already scraped this CIK\n",
    "    try:\n",
    "        os.mkdir(ticker)\n",
    "    except OSError:\n",
    "        text = f\"Already made folder for ticker {ticker}\"\n",
    "        WriteLogFile(log_file_name, text)\n",
    "    \n",
    "    # If we haven't, go into the directory for that CIK\n",
    "    os.chdir(ticker)\n",
    "        \n",
    "    # Request list of 10-K filings\n",
    "    res = requests.get(browse_url_base.format(cik))\n",
    "    \n",
    "    # If the request failed, log the failure and exit\n",
    "    if res.status_code != 200:\n",
    "        os.chdir('..')\n",
    "        os.rmdir(cik) # remove empty dir\n",
    "        text = \"Request failed with error code \" + str(res.status_code) + \\\n",
    "               \"\\nFailed URL: \" + (browse_url_base.format(cik)) + '\\n'\n",
    "        WriteLogFile(log_file_name, text)\n",
    "        return\n",
    "\n",
    "    # If the request doesn't fail, continue...\n",
    "    \n",
    "    # Parse the response HTML using BeautifulSoup\n",
    "    soup = bs.BeautifulSoup(res.text, \"lxml\")\n",
    "\n",
    "    # Extract all tables from the response\n",
    "    html_tables = soup.find_all('table')\n",
    "    \n",
    "    # Check that the table we're looking for exists\n",
    "    # If it doesn't, exit\n",
    "    if len(html_tables)<3:\n",
    "        os.chdir('..')\n",
    "        return\n",
    "    \n",
    "    # Parse the Filings table\n",
    "    filings_table = pd.read_html(str(html_tables[2]), header=0)[0]\n",
    "    filings_table['Filings'] = [str(x) for x in filings_table['Filings']]\n",
    "\n",
    "    # Get only 10-K and 10-K405 document filings\n",
    "    if is10K:\n",
    "        filings_table = filings_table[(filings_table['Filings'] == '10-K') | (filings_table['Filings'] == '10-K405')]\n",
    "    else:\n",
    "        filings_table = filings_table[(filings_table['Filings'] == '10-Q')]\n",
    "        \n",
    "    # If filings table doesn't have any\n",
    "    # 10-Ks or 10-K405s, exit\n",
    "    if len(filings_table)==0:\n",
    "        os.chdir('..')\n",
    "        return\n",
    "    \n",
    "    # Get accession number for each 10-K and 10-K405 filing\n",
    "    filings_table['Acc_No'] = [x.replace('\\xa0',' ')\n",
    "                               .split('Acc-no: ')[1]\n",
    "                               .split(' ')[0] for x in filings_table['Description']]\n",
    "\n",
    "    num_files_scraped = 0\n",
    "    \n",
    "    # Iterate through each filing and \n",
    "    # scrape the corresponding document...\n",
    "    for index, row in filings_table.iterrows():\n",
    "        \n",
    "        # Get the accession number for the filing\n",
    "        acc_no = str(row['Acc_No'])\n",
    "        \n",
    "        # Navigate to the page for the filing\n",
    "        docs_page = requests.get(filing_url_base.format(cik, acc_no))\n",
    "        \n",
    "        # If request fails, log the failure\n",
    "        # and skip to the next filing\n",
    "        if docs_page.status_code != 200:\n",
    "            os.chdir('..')\n",
    "            text = \"Request failed with error code \" + str(docs_page.status_code) + \\\n",
    "                   \"\\nFailed URL: \" + (filing_url_base.format(cik, acc_no)) + '\\n'\n",
    "            WriteLogFile(log_file_name, text)\n",
    "            os.chdir(cik)\n",
    "            continue\n",
    "\n",
    "        # If request succeeds, keep going...\n",
    "        \n",
    "        # Parse the table of documents for the filing\n",
    "        docs_page_soup = bs.BeautifulSoup(docs_page.text, 'lxml')\n",
    "        \n",
    "        filing_date_div = docs_page_soup.find(text=re.compile(\"Filing (D|d)ate\")).parent\n",
    "        filing_date = filing_date_div.findNext('div').get_text()\n",
    "        period_of_report_div = docs_page_soup.find(text=re.compile(\"Period (O|o)f (R|r)eport\")).parent\n",
    "        period_of_report_date = period_of_report_div.findNext('div').get_text()\n",
    "        \n",
    "        if is10K:\n",
    "            ticker_cik_df.at[ticker, f'10-K #{num_files_scraped + 1} Filing Date'] = filing_date\n",
    "            ticker_cik_df.at[ticker, f'10-K #{num_files_scraped + 1} Period'] = period_of_report_date\n",
    "        else:\n",
    "            ticker_cik_df.at[ticker, f'10-Q #{num_files_scraped + 1} Filing Date'] = filing_date\n",
    "            ticker_cik_df.at[ticker, f'10-Q #{num_files_scraped + 1} Period'] = period_of_report_date\n",
    "        \n",
    "        docs_html_tables = docs_page_soup.find_all('table')\n",
    "        if len(docs_html_tables)==0:\n",
    "            continue\n",
    "        docs_table = pd.read_html(str(docs_html_tables[0]), header=0)[0]\n",
    "        docs_table['Type'] = [str(x) for x in docs_table['Type']]\n",
    "        \n",
    "        # Get the 10-K and 10-K405 entries for the filing\n",
    "        if is10K:\n",
    "            docs_table = docs_table[(docs_table['Type'] == '10-K') | (docs_table['Type'] == '10-K405')]\n",
    "        else:\n",
    "            docs_table = docs_table[(docs_table['Type'] == '10-Q')]\n",
    "        # If there aren't any 10-K or 10-K405 entries,\n",
    "        # skip to the next filing\n",
    "        if len(docs_table)==0:\n",
    "            continue\n",
    "        # If there are 10-K or 10-K405 entries,\n",
    "        # grab the first document\n",
    "        elif len(docs_table)>0:\n",
    "            docs_table = docs_table.iloc[0]\n",
    "        \n",
    "        docname = docs_table['Document']\n",
    "        \n",
    "        # If that first entry is unavailable,\n",
    "        # log the failure and exit\n",
    "        if str(docname) == 'nan':\n",
    "            os.chdir('..')\n",
    "            text = 'File with CIK: {} and Acc_No: {} is unavailable'.format(cik, acc_no) + '\\n'\n",
    "            WriteLogFile(log_file_name, text)\n",
    "            os.chdir(cik)\n",
    "            continue       \n",
    "        \n",
    "        # If it is available, continue...\n",
    "        docname = docname.split()[0]\n",
    "        # Request the file\n",
    "        file = requests.get(doc_url_base.format(cik, acc_no.replace('-', ''), docname))\n",
    "        \n",
    "        # If the request fails, log the failure and exit\n",
    "        if file.status_code != 200:\n",
    "            os.chdir('..')\n",
    "            text = \"Request failed with error code \" + str(file.status_code) + \\\n",
    "                   \"\\nFailed URL: \" + (doc_url_base.format(cik, acc_no.replace('-', ''), docname)) + '\\n'\n",
    "            WriteLogFile(log_file_name, text)\n",
    "            os.chdir(cik)\n",
    "            continue\n",
    "        \n",
    "        # If it succeeds, keep going...\n",
    "        \n",
    "        # Save the file in appropriate format\n",
    "        if '.txt' in docname:\n",
    "            # Save text as TXT\n",
    "            date = str(row['Filing Date'])\n",
    "            filename = cik + '_' + date + '.txt'\n",
    "            html_file = open(filename, 'w')\n",
    "            html_file.write(file.text)\n",
    "            html_file.close()\n",
    "        else:\n",
    "            # Save text as HTML\n",
    "            date = str(row['Filing Date'])\n",
    "            filename = cik + '_' + date + '.html'\n",
    "            html_file = open(filename, 'w')\n",
    "            html_file.write(file.text)\n",
    "            html_file.close()\n",
    "           \n",
    "        num_files_scraped = num_files_scraped + 1\n",
    "        \n",
    "        if num_files_scraped == num_files_to_scrape:\n",
    "            break\n",
    "        \n",
    "    # Move back to the main 10-K directory\n",
    "    os.chdir('..')\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def delete_contents(foldername):\n",
    "    for root, dirs, files in os.walk(foldername):\n",
    "        for f in files:\n",
    "            os.unlink(os.path.join(root, f))\n",
    "        for d in dirs:\n",
    "            shutil.rmtree(os.path.join(root, d))\n",
    "        \n",
    "\n",
    "\n",
    "delete_contents(pathname_10k)\n",
    "delete_contents(pathname_10q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500it [45:17,  5.43s/it]\n"
     ]
    }
   ],
   "source": [
    "os.chdir(original_directory)\n",
    "# Run the function to scrape 10-K\n",
    "# Define parameters\n",
    "browse_url_base_10k = 'https://www.sec.gov/cgi-bin/browse-edgar?action=getcompany&CIK={}&type=10-K'\n",
    "filing_url_base_10k = 'http://www.sec.gov/Archives/edgar/data/{}/{}-index.html'\n",
    "doc_url_base_10k = 'http://www.sec.gov/Archives/edgar/data/{}/{}/{}'\n",
    "\n",
    "# Set correct directory\n",
    "os.chdir(pathname_10k)\n",
    "\n",
    "# Initialize log file\n",
    "# (log file name = the time we initiate scraping session)\n",
    "time = strftime(\"%Y-%m-%d %Hh%Mm%Ss\", gmtime())\n",
    "log_file_name = 'log '+time+'.txt'\n",
    "with open(log_file_name, 'a') as log_file:\n",
    "    log_file.close()\n",
    "\n",
    "# Iterate over CIKs and scrape 10-Ks\n",
    "for ticker,row in tqdm(ticker_cik_df.iterrows()):\n",
    "    try:\n",
    "        ScrapeDocument(ticker=ticker,\n",
    "                       browse_url_base=browse_url_base_10k, \n",
    "                       filing_url_base=filing_url_base_10k, \n",
    "                       doc_url_base=doc_url_base_10k, \n",
    "                       cik=row['cik'],\n",
    "                       log_file_name=log_file_name,\n",
    "                       is10K = True,\n",
    "                       num_files_to_scrape = 2)\n",
    "    except:\n",
    "        WriteLogFile(log_file_name, f\"Exception on {ticker}\")\n",
    "os.chdir(original_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500it [1:35:54, 11.51s/it]\n"
     ]
    }
   ],
   "source": [
    "os.chdir(original_directory)\n",
    "# Run the function to scrape 10-Qs\n",
    "# Define parameters\n",
    "browse_url_base_10q = 'https://www.sec.gov/cgi-bin/browse-edgar?action=getcompany&CIK={}&type=10-Q&count=1000'\n",
    "filing_url_base_10q = 'http://www.sec.gov/Archives/edgar/data/{}/{}-index.html'\n",
    "doc_url_base_10q = 'http://www.sec.gov/Archives/edgar/data/{}/{}/{}'\n",
    "\n",
    "# Set correct directory\n",
    "os.chdir(pathname_10q)\n",
    "\n",
    "# Initialize log file\n",
    "# (log file name = the time we initiate scraping session)\n",
    "time = strftime(\"%Y-%m-%d %Hh%Mm%Ss\", gmtime())\n",
    "log_file_name = 'log '+time+'.txt'\n",
    "with open(log_file_name, 'a') as log_file:\n",
    "    log_file.close()\n",
    "\n",
    "# Iterate over CIKs and scrape 10-Ks\n",
    "for ticker,row in tqdm(ticker_cik_df.iterrows()):\n",
    "    try:\n",
    "        ScrapeDocument(ticker=ticker,\n",
    "                       browse_url_base=browse_url_base_10q, \n",
    "                       filing_url_base=filing_url_base_10q, \n",
    "                       doc_url_base=doc_url_base_10q, \n",
    "                       cik=row['cik'],\n",
    "                       log_file_name=log_file_name,\n",
    "                       is10K = False,\n",
    "                       num_files_to_scrape = 6)\n",
    "    except:\n",
    "        WriteLogFile(log_file_name, f\"Exception on {ticker}\")\n",
    "    \n",
    "os.chdir(original_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cik</th>\n",
       "      <th>10-K #1 Filing Date</th>\n",
       "      <th>10-K #1 Period</th>\n",
       "      <th>10-K #2 Filing Date</th>\n",
       "      <th>10-K #2 Period</th>\n",
       "      <th>10-Q #1 Filing Date</th>\n",
       "      <th>10-Q #1 Period</th>\n",
       "      <th>10-Q #2 Filing Date</th>\n",
       "      <th>10-Q #2 Period</th>\n",
       "      <th>10-Q #3 Filing Date</th>\n",
       "      <th>10-Q #3 Period</th>\n",
       "      <th>10-Q #4 Filing Date</th>\n",
       "      <th>10-Q #4 Period</th>\n",
       "      <th>10-Q #5 Filing Date</th>\n",
       "      <th>10-Q #5 Period</th>\n",
       "      <th>10-Q #6 Filing Date</th>\n",
       "      <th>10-Q #6 Period</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ticker</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mmm</th>\n",
       "      <td>0000066740</td>\n",
       "      <td>2020-02-06</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>2019-02-07</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>2020-04-28</td>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>2019-10-25</td>\n",
       "      <td>2019-09-30</td>\n",
       "      <td>2019-07-26</td>\n",
       "      <td>2019-06-30</td>\n",
       "      <td>2019-04-26</td>\n",
       "      <td>2019-03-31</td>\n",
       "      <td>2018-10-25</td>\n",
       "      <td>2018-09-30</td>\n",
       "      <td>2018-07-26</td>\n",
       "      <td>2018-06-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abt</th>\n",
       "      <td>0000001800</td>\n",
       "      <td>2020-02-21</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>2019-02-22</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>2020-04-29</td>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>2019-10-31</td>\n",
       "      <td>2019-09-30</td>\n",
       "      <td>2019-07-31</td>\n",
       "      <td>2019-06-30</td>\n",
       "      <td>2019-05-01</td>\n",
       "      <td>2019-03-31</td>\n",
       "      <td>2018-10-31</td>\n",
       "      <td>2018-09-30</td>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>2018-06-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbv</th>\n",
       "      <td>0001551152</td>\n",
       "      <td>2020-02-21</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>2019-02-27</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>2020-05-08</td>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>2019-11-06</td>\n",
       "      <td>2019-09-30</td>\n",
       "      <td>2019-08-05</td>\n",
       "      <td>2019-06-30</td>\n",
       "      <td>2019-05-03</td>\n",
       "      <td>2019-03-31</td>\n",
       "      <td>2018-11-07</td>\n",
       "      <td>2018-09-30</td>\n",
       "      <td>2018-08-07</td>\n",
       "      <td>2018-06-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abmd</th>\n",
       "      <td>0000815094</td>\n",
       "      <td>2020-05-21</td>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>2019-05-23</td>\n",
       "      <td>2019-03-31</td>\n",
       "      <td>2020-02-06</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>2019-10-31</td>\n",
       "      <td>2019-09-30</td>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>2019-06-30</td>\n",
       "      <td>2019-02-05</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>2018-11-06</td>\n",
       "      <td>2018-09-30</td>\n",
       "      <td>2018-08-02</td>\n",
       "      <td>2018-06-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acn</th>\n",
       "      <td>0001467373</td>\n",
       "      <td>2019-10-29</td>\n",
       "      <td>2019-08-31</td>\n",
       "      <td>2018-10-24</td>\n",
       "      <td>2018-08-31</td>\n",
       "      <td>2020-03-19</td>\n",
       "      <td>2020-02-29</td>\n",
       "      <td>2019-12-19</td>\n",
       "      <td>2019-11-30</td>\n",
       "      <td>2019-06-27</td>\n",
       "      <td>2019-05-31</td>\n",
       "      <td>2019-03-28</td>\n",
       "      <td>2019-02-28</td>\n",
       "      <td>2018-12-20</td>\n",
       "      <td>2018-11-30</td>\n",
       "      <td>2018-06-28</td>\n",
       "      <td>2018-05-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               cik 10-K #1 Filing Date 10-K #1 Period 10-K #2 Filing Date  \\\n",
       "ticker                                                                      \n",
       "mmm     0000066740          2020-02-06     2019-12-31          2019-02-07   \n",
       "abt     0000001800          2020-02-21     2019-12-31          2019-02-22   \n",
       "abbv    0001551152          2020-02-21     2019-12-31          2019-02-27   \n",
       "abmd    0000815094          2020-05-21     2020-03-31          2019-05-23   \n",
       "acn     0001467373          2019-10-29     2019-08-31          2018-10-24   \n",
       "\n",
       "       10-K #2 Period 10-Q #1 Filing Date 10-Q #1 Period 10-Q #2 Filing Date  \\\n",
       "ticker                                                                         \n",
       "mmm        2018-12-31          2020-04-28     2020-03-31          2019-10-25   \n",
       "abt        2018-12-31          2020-04-29     2020-03-31          2019-10-31   \n",
       "abbv       2018-12-31          2020-05-08     2020-03-31          2019-11-06   \n",
       "abmd       2019-03-31          2020-02-06     2019-12-31          2019-10-31   \n",
       "acn        2018-08-31          2020-03-19     2020-02-29          2019-12-19   \n",
       "\n",
       "       10-Q #2 Period 10-Q #3 Filing Date 10-Q #3 Period 10-Q #4 Filing Date  \\\n",
       "ticker                                                                         \n",
       "mmm        2019-09-30          2019-07-26     2019-06-30          2019-04-26   \n",
       "abt        2019-09-30          2019-07-31     2019-06-30          2019-05-01   \n",
       "abbv       2019-09-30          2019-08-05     2019-06-30          2019-05-03   \n",
       "abmd       2019-09-30          2019-08-01     2019-06-30          2019-02-05   \n",
       "acn        2019-11-30          2019-06-27     2019-05-31          2019-03-28   \n",
       "\n",
       "       10-Q #4 Period 10-Q #5 Filing Date 10-Q #5 Period 10-Q #6 Filing Date  \\\n",
       "ticker                                                                         \n",
       "mmm        2019-03-31          2018-10-25     2018-09-30          2018-07-26   \n",
       "abt        2019-03-31          2018-10-31     2018-09-30          2018-08-01   \n",
       "abbv       2019-03-31          2018-11-07     2018-09-30          2018-08-07   \n",
       "abmd       2018-12-31          2018-11-06     2018-09-30          2018-08-02   \n",
       "acn        2019-02-28          2018-12-20     2018-11-30          2018-06-28   \n",
       "\n",
       "       10-Q #6 Period  \n",
       "ticker                 \n",
       "mmm        2018-06-30  \n",
       "abt        2018-06-30  \n",
       "abbv       2018-06-30  \n",
       "abmd       2018-06-30  \n",
       "acn        2018-05-31  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ticker_cik_df.to_csv('ticker_data.csv')\n",
    "ticker_cik_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Scrape text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir(original_directory)\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "negative_score = -4.0\n",
    "positive_score = 0.0\n",
    "uncertain_score = -2.0\n",
    "\n",
    "negative_words = pd.read_csv('LoughranMcDonald_SentimentWordLists_Negative.csv', header=None).iloc[:,0]\n",
    "positive_words = pd.read_csv('LoughranMcDonald_SentimentWordLists_Positive.csv', header=None).iloc[:,0]\n",
    "uncertain_words = pd.read_csv('LoughranMcDonald_SentimentWordLists_Uncertain.csv', header=None).iloc[:,0]\n",
    "\n",
    "negative_word_scores = {word.lower(): negative_score for word in negative_words}\n",
    "positive_word_scores = {word.lower(): positive_score for word in positive_words}\n",
    "uncertain_word_scores = {word.lower(): uncertain_score for word in uncertain_words}\n",
    "\n",
    "financial_word_dict = {**negative_word_scores, **positive_word_scores, **uncertain_word_scores}\n",
    "analyzer.lexicon.update(financial_word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_all_text(ticker, is10K, file_name):\n",
    "    try:\n",
    "        os.chdir(original_directory)\n",
    "        if is10K:\n",
    "            os.chdir(pathname_10k)\n",
    "        else:\n",
    "            os.chdir(pathname_10q)\n",
    "        os.chdir(ticker)\n",
    "        file_name_list = list(filter(lambda x: x.endswith(file_name + \".html\"), sorted(os.listdir(\".\"))))\n",
    "        if not file_name_list:\n",
    "            return []\n",
    "\n",
    "        full_file_name = file_name_list[0]\n",
    "\n",
    "        with open(full_file_name) as file:\n",
    "            soup = bs.BeautifulSoup(file, \"html.parser\")\n",
    "        [table.decompose() for table in soup.find_all(\"table\")]\n",
    "\n",
    "        cleaned = soup.get_text('\\n').replace('\\n', ' ')\n",
    "        os.chdir(original_directory)\n",
    "        return tokenize.sent_tokenize(cleaned)\n",
    "    except:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cik</th>\n",
       "      <th>10-K #1 Filing Date</th>\n",
       "      <th>10-K #1 Period</th>\n",
       "      <th>10-K #2 Filing Date</th>\n",
       "      <th>10-K #2 Period</th>\n",
       "      <th>10-Q #1 Filing Date</th>\n",
       "      <th>10-Q #1 Period</th>\n",
       "      <th>10-Q #2 Filing Date</th>\n",
       "      <th>10-Q #2 Period</th>\n",
       "      <th>10-Q #3 Filing Date</th>\n",
       "      <th>10-Q #3 Period</th>\n",
       "      <th>10-Q #4 Filing Date</th>\n",
       "      <th>10-Q #4 Period</th>\n",
       "      <th>10-Q #5 Filing Date</th>\n",
       "      <th>10-Q #5 Period</th>\n",
       "      <th>10-Q #6 Filing Date</th>\n",
       "      <th>10-Q #6 Period</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ticker</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mmm</th>\n",
       "      <td>66740</td>\n",
       "      <td>2020-02-06</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>2019-02-07</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>2020-04-28</td>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>2019-10-25</td>\n",
       "      <td>2019-09-30</td>\n",
       "      <td>2019-07-26</td>\n",
       "      <td>2019-06-30</td>\n",
       "      <td>2019-04-26</td>\n",
       "      <td>2019-03-31</td>\n",
       "      <td>2018-10-25</td>\n",
       "      <td>2018-09-30</td>\n",
       "      <td>2018-07-26</td>\n",
       "      <td>2018-06-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abt</th>\n",
       "      <td>1800</td>\n",
       "      <td>2020-02-21</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>2019-02-22</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>2020-04-29</td>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>2019-10-31</td>\n",
       "      <td>2019-09-30</td>\n",
       "      <td>2019-07-31</td>\n",
       "      <td>2019-06-30</td>\n",
       "      <td>2019-05-01</td>\n",
       "      <td>2019-03-31</td>\n",
       "      <td>2018-10-31</td>\n",
       "      <td>2018-09-30</td>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>2018-06-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbv</th>\n",
       "      <td>1551152</td>\n",
       "      <td>2020-02-21</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>2019-02-27</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>2020-05-08</td>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>2019-11-06</td>\n",
       "      <td>2019-09-30</td>\n",
       "      <td>2019-08-05</td>\n",
       "      <td>2019-06-30</td>\n",
       "      <td>2019-05-03</td>\n",
       "      <td>2019-03-31</td>\n",
       "      <td>2018-11-07</td>\n",
       "      <td>2018-09-30</td>\n",
       "      <td>2018-08-07</td>\n",
       "      <td>2018-06-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abmd</th>\n",
       "      <td>815094</td>\n",
       "      <td>2020-05-21</td>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>2019-05-23</td>\n",
       "      <td>2019-03-31</td>\n",
       "      <td>2020-02-06</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>2019-10-31</td>\n",
       "      <td>2019-09-30</td>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>2019-06-30</td>\n",
       "      <td>2019-02-05</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>2018-11-06</td>\n",
       "      <td>2018-09-30</td>\n",
       "      <td>2018-08-02</td>\n",
       "      <td>2018-06-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acn</th>\n",
       "      <td>1467373</td>\n",
       "      <td>2019-10-29</td>\n",
       "      <td>2019-08-31</td>\n",
       "      <td>2018-10-24</td>\n",
       "      <td>2018-08-31</td>\n",
       "      <td>2020-03-19</td>\n",
       "      <td>2020-02-29</td>\n",
       "      <td>2019-12-19</td>\n",
       "      <td>2019-11-30</td>\n",
       "      <td>2019-06-27</td>\n",
       "      <td>2019-05-31</td>\n",
       "      <td>2019-03-28</td>\n",
       "      <td>2019-02-28</td>\n",
       "      <td>2018-12-20</td>\n",
       "      <td>2018-11-30</td>\n",
       "      <td>2018-06-28</td>\n",
       "      <td>2018-05-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            cik 10-K #1 Filing Date 10-K #1 Period 10-K #2 Filing Date  \\\n",
       "ticker                                                                   \n",
       "mmm       66740          2020-02-06     2019-12-31          2019-02-07   \n",
       "abt        1800          2020-02-21     2019-12-31          2019-02-22   \n",
       "abbv    1551152          2020-02-21     2019-12-31          2019-02-27   \n",
       "abmd     815094          2020-05-21     2020-03-31          2019-05-23   \n",
       "acn     1467373          2019-10-29     2019-08-31          2018-10-24   \n",
       "\n",
       "       10-K #2 Period 10-Q #1 Filing Date 10-Q #1 Period 10-Q #2 Filing Date  \\\n",
       "ticker                                                                         \n",
       "mmm        2018-12-31          2020-04-28     2020-03-31          2019-10-25   \n",
       "abt        2018-12-31          2020-04-29     2020-03-31          2019-10-31   \n",
       "abbv       2018-12-31          2020-05-08     2020-03-31          2019-11-06   \n",
       "abmd       2019-03-31          2020-02-06     2019-12-31          2019-10-31   \n",
       "acn        2018-08-31          2020-03-19     2020-02-29          2019-12-19   \n",
       "\n",
       "       10-Q #2 Period 10-Q #3 Filing Date 10-Q #3 Period 10-Q #4 Filing Date  \\\n",
       "ticker                                                                         \n",
       "mmm        2019-09-30          2019-07-26     2019-06-30          2019-04-26   \n",
       "abt        2019-09-30          2019-07-31     2019-06-30          2019-05-01   \n",
       "abbv       2019-09-30          2019-08-05     2019-06-30          2019-05-03   \n",
       "abmd       2019-09-30          2019-08-01     2019-06-30          2019-02-05   \n",
       "acn        2019-11-30          2019-06-27     2019-05-31          2019-03-28   \n",
       "\n",
       "       10-Q #4 Period 10-Q #5 Filing Date 10-Q #5 Period 10-Q #6 Filing Date  \\\n",
       "ticker                                                                         \n",
       "mmm        2019-03-31          2018-10-25     2018-09-30          2018-07-26   \n",
       "abt        2019-03-31          2018-10-31     2018-09-30          2018-08-01   \n",
       "abbv       2019-03-31          2018-11-07     2018-09-30          2018-08-07   \n",
       "abmd       2018-12-31          2018-11-06     2018-09-30          2018-08-02   \n",
       "acn        2019-02-28          2018-12-20     2018-11-30          2018-06-28   \n",
       "\n",
       "       10-Q #6 Period  \n",
       "ticker                 \n",
       "mmm        2018-06-30  \n",
       "abt        2018-06-30  \n",
       "abbv       2018-06-30  \n",
       "abmd       2018-06-30  \n",
       "acn        2018-05-31  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(original_directory)\n",
    "\n",
    "ticker_data = pd.read_csv('ticker_data.csv')\n",
    "ticker_data = ticker_data.set_index(\"ticker\")\n",
    "ticker_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [2:58:11<00:00, 21.38s/it]   \n"
     ]
    }
   ],
   "source": [
    "os.chdir(original_directory)\n",
    "\n",
    "def is_valid_date(date_str):\n",
    "    return type(date_str) is str\n",
    "    \n",
    "\n",
    "companies = list(ticker_data.index)\n",
    "rows_list = []\n",
    "DataSource = namedtuple(\"DataSource\", [\"is10K\", \"documentnumber\"])\n",
    "datasources = [DataSource(True, i) for i in range(1, 3)] + [DataSource(False, i) for i in range(1, 7)]\n",
    "rows_list = []\n",
    "for ticker in tqdm(companies):\n",
    "    for source in datasources:\n",
    "        prefix = \"10-K\" if source.is10K else \"10-Q\"\n",
    "        as_of_period = ticker_data.loc[ticker, f\"{prefix} #{source.documentnumber} Filing Date\"]\n",
    "        observation_period = ticker_data.loc[ticker, f\"{prefix} #{source.documentnumber} Period\"]\n",
    "        if not (is_valid_date(observation_period) and is_valid_date(observation_period)):\n",
    "            continue\n",
    "        sentences = get_all_text(ticker, source.is10K, as_of_period)\n",
    "        for i,sentence in enumerate(sentences):\n",
    "            new_row = {\"ticker\": ticker,\n",
    "                       'As Of Period': as_of_period, \n",
    "                       'Observation Period': observation_period,\n",
    "                       'Document Type': prefix,\n",
    "                       'Sentence ID': i, \n",
    "                       'Sentence': sentence[:5000]}\n",
    "            rows_list.append(new_row)\n",
    "sentences_df = pd.DataFrame(rows_list)                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3679838it [26:25, 2320.65it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>As Of Period</th>\n",
       "      <th>Document Type</th>\n",
       "      <th>Observation Period</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Sentence ID</th>\n",
       "      <th>ticker</th>\n",
       "      <th>compound</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-02-06</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>Common Stock, Par Value $.01 Per S...</td>\n",
       "      <td>0</td>\n",
       "      <td>mmm</td>\n",
       "      <td>0.9246</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.907</td>\n",
       "      <td>0.076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-02-06</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>Securities registered pursuant to section 12(g...</td>\n",
       "      <td>1</td>\n",
       "      <td>mmm</td>\n",
       "      <td>0.5267</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-02-06</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>Yes    ☒     No    ☐ ​ Indicate by check mark ...</td>\n",
       "      <td>2</td>\n",
       "      <td>mmm</td>\n",
       "      <td>0.1280</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.841</td>\n",
       "      <td>0.087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-02-06</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>Yes   ☐      No    ☒ ​ Indicate by check mark ...</td>\n",
       "      <td>3</td>\n",
       "      <td>mmm</td>\n",
       "      <td>0.4019</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.899</td>\n",
       "      <td>0.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-02-06</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>Yes    ☒     No   ☐ ​ Indicate by check mark w...</td>\n",
       "      <td>4</td>\n",
       "      <td>mmm</td>\n",
       "      <td>0.1280</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.914</td>\n",
       "      <td>0.047</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  As Of Period Document Type Observation Period  \\\n",
       "0   2020-02-06          10-K         2019-12-31   \n",
       "1   2020-02-06          10-K         2019-12-31   \n",
       "2   2020-02-06          10-K         2019-12-31   \n",
       "3   2020-02-06          10-K         2019-12-31   \n",
       "4   2020-02-06          10-K         2019-12-31   \n",
       "\n",
       "                                            Sentence  Sentence ID ticker  \\\n",
       "0              Common Stock, Par Value $.01 Per S...            0    mmm   \n",
       "1  Securities registered pursuant to section 12(g...            1    mmm   \n",
       "2  Yes    ☒     No    ☐ ​ Indicate by check mark ...            2    mmm   \n",
       "3  Yes   ☐      No    ☒ ​ Indicate by check mark ...            3    mmm   \n",
       "4  Yes    ☒     No   ☐ ​ Indicate by check mark w...            4    mmm   \n",
       "\n",
       "   compound    neg    neu    pos  \n",
       "0    0.9246  0.018  0.907  0.076  \n",
       "1    0.5267  0.000  0.872  0.128  \n",
       "2    0.1280  0.071  0.841  0.087  \n",
       "3    0.4019  0.031  0.899  0.070  \n",
       "4    0.1280  0.039  0.914  0.047  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(original_directory)\n",
    "\n",
    "for i, row in tqdm(sentences_df.iterrows()):\n",
    "    polarity_scores = analyzer.polarity_scores(row['Sentence'])\n",
    "    sentences_df.at[i, 'compound'] = polarity_scores['compound']\n",
    "    sentences_df.at[i, 'neg'] = polarity_scores['neg']\n",
    "    sentences_df.at[i, 'neu'] = polarity_scores['neu']\n",
    "    sentences_df.at[i, 'pos'] = polarity_scores['pos']\n",
    "sentences_df.to_csv('sentences_data.csv')\n",
    "sentences_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
